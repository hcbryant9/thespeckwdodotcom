<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects</title>
    
    <style>
        
        #kinectgraph2 {
            width:500px;
            height:400px;
        }
        #kinectgraph3 {
            width:650px;
            height:100px;
        }
        #kinectgraph4 {
            width:550px;
            height:100px;
        }
        #kinectgraph5 {
            width:400px;
            height:300px;
        }
       code{
        color: peru
       }
    </style>
    
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-QQ6JMSNG3C"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'G-QQ6JMSNG3C');
</script>
<body>
    <nav>
        <a href="index.html">Home</a>
    </nav>
    <center>    
    <p1>current featured project is...</p1>
    <br>
    <br>
    <p1>kinect-pure-data-unity</p1>
    <br>
    <br>
    <img id = "kinectgraph" src = "assets/images/kinect-image.jpg" alt ="kin1"/>
    <br>
    <a href="https://github.com/hcbryant9/KinectPD">Project GitHub</a>    
    <br>

    <br>
    <small>This program uses the joint-tracking of the xbox kinect to play a pure data patch within Unity. The program follows the players hands in the X and Y axis.
        The distance between the players hands in the X axis control the frequency of the melody while the distance in the Y axis control the frequency of the bass.
        The project was inspired by the theremin and other instruments controlled by movement rather than hitting a note or plucking a string. The goal was to create
        sounds based on the space we occupy.
    </small>
   
    <br>
    <br>
    <small>audio</small>
    <br>
    <img id = "kinectgraph2" src = "assets/images/pdPatch.JPG" alt ="pd1"/>
    <br>
    <br>
    <small>Here is the pure data patch... it's a frankenstein of a bunch of tutorials since I didn't know how to use it before starting. I intially went in thinking I would send midi values
        to a DAW but that's not so easy in Unity. Luckily, pd is open-source and some lovely people created a library to send floats to a pure data patch! The music was based off a
        song called faucet by a band called nash to stoudemire. Kind of just something to zone out and meditate to. The pure data patch changes the melody every 4 notes and the bass is changed every 8.
    </small>
    <br>
    <br>
    <small>code</small>
    <br>
    <script src="https://gist.github.com/hcbryant9/3e1a7ae39422bc2ec7bbf8488598420a.js"></script>
    <br>
    <br>
    <small>These are a little code samples... This snippit you can see the right hand's x,y,z position are getting stored into an array. The data can be taken from the kinect through the body class' joints
        method that has the coordinates for each joint seen in the image at the top of the page. 
    </small>
    <br>
    <br>
    <script src="https://gist.github.com/hcbryant9/dbd6cebe59c453d3ffbb9c15a408ebdf.js"></script>
    <br>
    <small>This snippit is the main functionality of the program. We can calculate the magnitude, or distance, of the hands
        by subtracting the x coordinate of the right from the x coordinate of the left and then taking the absolute value (I did the same thing for the y). The magnitude goes through some checks to see which
        note should be sent. In this case the magnitude is between 0 and .2 . </small>
    <br>
    <img id = "kinectgraph5" src = "assets/images/kinectss5.png" alt ="kin4"/>
    <br>
    <small>When the player holds their hands close together, the magnitude will be ~0.2f and at full stretch it can get up to 1.5f. The same can be said for spreading your arms on the y axis.
        That gave me about 7 even slots in the X and 7 in the Y where we can play notes. That might sound funny, but maybe the next picture will make more sense.
    </small>
    <br>
    <img id = "kinectgraph5" src = "assets/images/kinectss6.png" alt ="kin4"/>
    <br>
    <small>So for example if this player put both their hands in the yellow zone, they'd play an E with the frequency 329.6. Note that if the player had their left hand in the red and right in the purple, it would
        be the same as the plaer have both hands in the green! Also note that the same thing is done in the y for the bass. The notes are stored in two different arrays and are converted to floats and sent to the patch depending on the magnitude.
         The notes are based off a C major scale!!
    </small>
    <br>
    <br>
    <small>visuals</small>
    <br>
    <img id = "kinectgraph5" src = "assets/images/kinectss11.JPG" alt ="kin11"/>
    <img id = "kinectgraph5" src = "assets/images/kinectss12.JPG" alt ="kin12"/>
    <br>
    <small>The visuals were made using my analog video distorter along with my hi8 camcorder
    </small>
    <br>
    <br>
    <small>here is an example of what it looked like</small>
    <br>
    <img id = "kinectgraph5" src = "assets/images/kinectss14.JPG" alt ="kin14"/>
    <br>
    <br>
    <small>additions</small>
    <br>
    <small>I had to stop working on this project since school projects are kicking my butt, but I'd like to continue working on it 
        and give the visualization a little more personality because the style of is nothing new/not very exciting. Let me know if you enjoyed
        or have any questions, maybe I'll set up a demo for people to play bc it is pretty mesmerizing
    </small>
    <br>
    <br>
   
    <br>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/sTX8tUjffws?si=hiRv-oET4h4L7LDc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    <br>
    
    
</center>

</body>
</html>